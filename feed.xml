<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://kamalpatell.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://kamalpatell.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-12-04T13:42:44+00:00</updated><id>https://kamalpatell.github.io/feed.xml</id><title type="html">blank</title><subtitle></subtitle><entry><title type="html">PyTorch Linear Regression Model</title><link href="https://kamalpatell.github.io/blog/2024/pytorch-linear-regression/" rel="alternate" type="text/html" title="PyTorch Linear Regression Model"/><published>2024-06-23T12:00:00+00:00</published><updated>2024-06-23T12:00:00+00:00</updated><id>https://kamalpatell.github.io/blog/2024/pytorch-linear-regression</id><content type="html" xml:base="https://kamalpatell.github.io/blog/2024/pytorch-linear-regression/"><![CDATA[<h3 id="pytorch">PyTorch</h3> <p>PyTorch is a scalable and multiplatform programming interface for implementing and running machine learning algorithms. PyTorch is primarily developed at Facebook AI Research lab. Many machine learning researchers and practitioners from academia and industry have adapted <a href="https://pytorch.org/">PyTorch</a> to develop deep learning solutions, such as Tesla Autopilot, Uber’s Pyro, and Hugging Face’s Transformers.</p> <h3 id="tensors">Tensors</h3> <p>Tensors are the fundamentals data structures used in machine learning, in context of data science tensors are multi-dimensional arrays of numbers that represent complex data.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/ml/tensor-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/ml/tensor-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/ml/tensor-1400.webp"/> <img src="/assets/img/blog/ml/tensor.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Dimensions of Tensors in PyTorch. photo from <a href="https://learnopencv.com/pytorch-for-beginners-basics" target="blank_">learnopencv</a> </div> <h4 id="1d-tensor">1D Tensor</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># Create a 1D tensor (vector)
</span><span class="n">tensor_1d</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="nf">print</span><span class="p">(</span><span class="n">tensor_1d</span><span class="p">)</span>

</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">tensor([1, 2, 3, 4, 5])</code></p> <h4 id="2d-tensor">2D Tensor</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create a 2D tensor (matrix)
</span><span class="n">tensor_2d</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]])</span>
<span class="nf">print</span><span class="p">(</span><span class="n">tensor_2d</span><span class="p">)</span>

</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])</code></p> <h4 id="3d-tensor">3D Tensor</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tensor_3d</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]],</span>
                          <span class="p">[[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">]]])</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">tensor([[[ 1, 2, 3], [ 4, 5, 6]], [[ 7, 8, 9], [10, 11, 12]]])</code></p> <h3 id="linear-regression-model">Linear Regression Model</h3> <p>At its core, linear regression seeks to establish a linear relationship between a dependent variable (often denoted as ( y )) and one or more independent variables (denoted as ( x )). The simplest form, simple linear regression, involves a single independent variable and is represented by the equation:</p> \[y = \beta_0 + \beta_1 x + \epsilon\] <p>where:</p> <ul> <li>\(( y )\) is the dependent variable.</li> <li>\(( x )\) is the independent variable.</li> <li>\(( \beta_0 )\) is the y-intercept of the regression line.</li> <li>\(( \beta_1 )\) is the slope of the regression line.</li> <li>\(( \epsilon )\) is the error term, accounting for the variability in ( y ) that ( x ) cannot explain.</li> </ul> <p>In multiple linear regression, the model extends to include multiple independent variables, and the equation becomes:</p> \[y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_n x_n + \epsilon\] <p>where:</p> <ul> <li>\(( y )\) is the dependent variable.</li> <li>\(( x_1, x_2, \ldots, x_n )\) are the independent variables.</li> <li>\(( \beta_0 \ )\) is the y-intercept of the regression plane.</li> <li>\(( \beta_1, \beta_2, \ldots, \beta_n )\) are the coefficients representing the impact of each independent variable.</li> <li>\(( \epsilon )\) is the error term.</li> </ul> <p>The goal of linear regression is to determine the optimal values of \(( \beta_0, \beta_1, \ldots, \beta_n )\) that minimize the sum of squared differences between the observed values and the values predicted by the model, known as the residual sum of squares (RSS). This optimization is typically performed using methods such as Ordinary Least Squares (OLS).</p> <p>Linear regression provides a straightforward yet powerful approach to predictive modeling, making it a cornerstone technique in the field of data science.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="sh">"</span><span class="s">float32</span><span class="sh">"</span><span class="p">).</span><span class="nf">reshape</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mf">5.1</span><span class="p">,</span>
                    <span class="mf">6.3</span><span class="p">,</span> <span class="mf">6.6</span><span class="p">,</span><span class="mf">7.4</span><span class="p">,</span> <span class="mf">8.7</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">])</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="sh">'</span><span class="s">*</span><span class="sh">'</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">x</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">y</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/ml/linear-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/ml/linear-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/ml/linear-1400.webp"/> <img src="/assets/img/blog/ml/linear.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Scatter plot </div> <p>we will standardize the features (mean centering and dividing by the standard deviation)</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="kn">from</span> <span class="n">torch.utils.data</span> <span class="kn">import</span> <span class="n">TensorDataset</span>
<span class="kn">from</span> <span class="n">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="n">X_train_norm</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_train</span> <span class="o">-</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">X_train</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nf">std</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_train_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">X_train_norm</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">train_ds</span> <span class="o">=</span> <span class="nc">TensorDataset</span><span class="p">(</span><span class="n">X_train_norm</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">train_dl</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">train_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

</code></pre></div></div> <p>Now, we can define our model for linear regression as $z = wx + b$. Here we will use the <code class="language-plaintext highlighter-rouge">torch.nn</code> module as it provides predefined layer for building complex NN models and use stochastic gradient descent as the optimizer from <code class="language-plaintext highlighter-rouge">torch.optim</code> modules.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">weight</span><span class="p">.</span><span class="nf">requies_grad_</span><span class="p">()</span>
<span class="n">bias</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">requies_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

</code></pre></div></div> <p>Here we initialized weight and bias vector. After defining the model we need to define loss function that we want to minimize to find optimal weight. We will choose mean squared error (MSE) as our loss function.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">MSELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="p">)</span>
<span class="n">input_size</span><span class="p">,</span> <span class="n">output_size</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">200</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">SGD</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

</code></pre></div></div> <p>Note, we used <code class="language-plaintext highlighter-rouge">torch.nn.Linear</code> class for linear layer to perform $z = wx + b$ calculation. Now, we can call step() method of the optimizer to train the model and pass batched dataset we created above.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="n">train_dl</span><span class="p">:</span>
        <span class="c1"># 1. Generate predictions
</span>        <span class="n">pred</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">x_batch</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">]</span>

        <span class="c1"># 2. Calculate loss
</span>        <span class="n">loss</span> <span class="o">=</span> <span class="nf">loss_fn</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>

        <span class="c1"># 3. Compute gradients
</span>        <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>

        <span class="c1"># 4. Update parameters using gradients
</span>        <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>

        <span class="c1"># 5. Reset the gradients to zero
</span>        <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">log_epochs</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s"> Loss </span><span class="si">{</span><span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p>After the model is trained we can check the weight and bias parameters</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Final Paremeters:</span><span class="sh">"</span><span class="p">,</span> <span class="n">model</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="nf">item</span><span class="p">(),</span> <span class="n">model</span><span class="p">.</span><span class="n">bias</span><span class="p">.</span><span class="nf">item</span><span class="p">())</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">Final Paremeters: 2.419365882873535 5.718400955200195</code></p> <p>For the test data, we created NumPy array of values evenly spaced between 0 and 9 and apply the same standardization features as the train dataset.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="c1"># Test data
</span><span class="n">X_test</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="sh">'</span><span class="s">float32</span><span class="sh">'</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">X_test_norm</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_test</span> <span class="o">-</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">X_train</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nf">std</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">X_test_norm</span><span class="p">)</span>

<span class="c1"># Prediction
</span><span class="n">y_pred</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">X_test_norm</span><span class="p">).</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>

<span class="c1"># Plot
</span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="nf">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">X_train_norm</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="sh">'</span><span class="s">o</span><span class="sh">'</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">X_test_norm</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="sh">'</span><span class="s">--</span><span class="sh">'</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">([</span><span class="sh">'</span><span class="s">Training examples</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Linear reg.</span><span class="sh">'</span><span class="p">])</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">x</span><span class="sh">'</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="sh">'</span><span class="s">both</span><span class="sh">'</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="sh">'</span><span class="s">major</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/ml/model_fit-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/ml/model_fit-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/ml/model_fit-1400.webp"/> <img src="/assets/img/blog/ml/model_fit.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> The Linear regression model fits the data </div>]]></content><author><name></name></author><category term="machine-learning"/><category term="PyTorch"/><summary type="html"><![CDATA[PyTorch]]></summary></entry><entry><title type="html">Linear Programming Using LpSolve and LpSolveAPI</title><link href="https://kamalpatell.github.io/blog/2024/lpSolve-R/" rel="alternate" type="text/html" title="Linear Programming Using LpSolve and LpSolveAPI"/><published>2024-01-30T13:00:00+00:00</published><updated>2024-01-30T13:00:00+00:00</updated><id>https://kamalpatell.github.io/blog/2024/lpSolve-R</id><content type="html" xml:base="https://kamalpatell.github.io/blog/2024/lpSolve-R/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>The LpSolveAPI and lpSolve are package provides in R to solve Mixed Integer Linear Programming (MILP) with support for for pure linear, (mixed) integer/binary, semi-continuous models.</p> <p><strong>Structure of linear program model</strong> The linear programming problem consists in optimizing (that is, either minimize or maximize) the value of a linear objective function of a vector of decision variables, considering that the variables can only take the values defined by a set of linear constraints. Linear programming is a case of mathematical programming, where objective function and constraints are linear.</p> <p>A formulation of a linear program in its canonical form is:</p> \[\begin{align*} \text{Maximize} \quad &amp;z = c_1x_1 + c_2x_2 + \ldots + c_nx_n \\ \text{Subject to} \quad &amp;a_{11}x_1 + a_{12}x_2 + \ldots + a_{1n}x_n \leq b_1 \\ &amp;a_{21}x_1 + a_{22}x_2 + \ldots + a_{2n}x_n \leq b_2 \\ &amp;\vdots \\ &amp;a_{m1}x_1 + a_{m2}x_2 + \ldots + a_{mn}x_n \leq b_m \\ &amp;x_1, x_2, \ldots, x_n \geq 0 \end{align*}\] <p>The model has the following elements:</p> <ul> <li> <p>An objective function of n decision variables \(x_j\). Decision variables are affected by cost coeffecient \(c_j\)</p> </li> <li> <p>It also encompasses a set of <code class="language-plaintext highlighter-rouge">m</code> constraints. In these constraints, a linear combination of the variables affected by coefficients \(a_{ij}\) must be less than or equal to its corresponding right-hand side value \(b_i\). Constraints may have signs greater than or equal, and equalities are also permissible.</p> </li> <li> <p>The bounds of the decision variables, in this case all decision variables has to be non-negative.</p> </li> </ul> <h2 id="problem-statement">Problem Statement</h2> <p>“This example of linear optimization can be found in the book “Modeling and Solving Linear Programming with R” by Jose M. Sallan, Oriol Lordan and Vincenc Fernandez. The example is named “Production of two models of chairs” and can be found at page 57, section 3.5.</p> <p>A company produces two models of chairs: 4P and 3P. The model 4P needs 4 legs, 1 seat and 1 back. On the other hand, the model 3P needs 3 legs and 1 seat. The company has a initial stock of 200 legs, 500 seats and 100 backs. If the company needs more legs, seats and backs, it can buy standard wood blocks, whose cost is 80 euro per block. The company can produce 10 seats, 20 legs and 2 backs from a standard wood block. The cost of producing the model 4P is 30 euro/chair, meanwhile the cost of the model 3P is 40 euro/chair. Finally, the company informs that the minimum number of chairs to produce is 1000 units per month. Define a linear programming model, which minimizes the total cost (the production costs of the two chairs, plus the buying of new wood blocks).</p> <h2 id="lpsolve-solution">lpSolve Solution</h2> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">lpSolve</span><span class="p">)</span><span class="w">

</span><span class="n">C</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">30</span><span class="p">,</span><span class="w"> </span><span class="m">40</span><span class="p">,</span><span class="w"> </span><span class="m">80</span><span class="p">)</span><span class="w">

</span><span class="c1"># Create constraint martix B</span><span class="w">
</span><span class="n">A</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">matrix</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">-10</span><span class="p">,</span><span class="w">
              </span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="m">-20</span><span class="p">,</span><span class="w">
              </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">-2</span><span class="p">,</span><span class="w">
              </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="p">),</span><span class="w"> </span><span class="n">nrow</span><span class="o">=</span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="n">byrow</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span><span class="w">

</span><span class="c1"># Right hand side for the constraints</span><span class="w">
</span><span class="n">B</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">500</span><span class="p">,</span><span class="w"> </span><span class="m">200</span><span class="p">,</span><span class="w"> </span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="m">1000</span><span class="p">)</span><span class="w">

</span><span class="c1"># Direction of the constraints</span><span class="w">
</span><span class="n">constranints_direc</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"&lt;="</span><span class="p">,</span><span class="w"> </span><span class="s2">"&lt;="</span><span class="p">,</span><span class="w"> </span><span class="s2">"&lt;="</span><span class="p">,</span><span class="w"> </span><span class="s2">"&gt;="</span><span class="p">)</span><span class="w">

</span><span class="c1"># Find the optimal solution</span><span class="w">
</span><span class="n">optimal</span><span class="w"> </span><span class="o">&lt;-</span><span class="w">  </span><span class="n">lp</span><span class="p">(</span><span class="n">direction</span><span class="o">=</span><span class="s2">"min"</span><span class="p">,</span><span class="w">
               </span><span class="n">objective.in</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">C</span><span class="p">,</span><span class="w">
               </span><span class="n">const.mat</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">A</span><span class="p">,</span><span class="w">
               </span><span class="n">const.dir</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">constranints_direc</span><span class="p">,</span><span class="w">
               </span><span class="n">const.rhs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">B</span><span class="p">,</span><span class="w">
               </span><span class="n">all.int</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">T</span><span class="p">)</span><span class="w">

</span><span class="n">str</span><span class="p">(</span><span class="n">optimal</span><span class="p">)</span><span class="w">

</span><span class="n">print</span><span class="p">(</span><span class="n">optimal</span><span class="o">$</span><span class="n">status</span><span class="p">)</span><span class="w">

</span><span class="c1"># Display the optimum value</span><span class="w">
</span><span class="n">best_solution</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">optimal</span><span class="o">$</span><span class="n">solution</span><span class="w">
</span><span class="nf">names</span><span class="p">(</span><span class="n">best_solution</span><span class="p">)</span><span class="w">
</span><span class="n">print</span><span class="p">(</span><span class="n">best_solution</span><span class="p">)</span><span class="w">

</span><span class="c1"># Check the value of objective function at optimal point</span><span class="w">
</span><span class="n">print</span><span class="p">(</span><span class="n">paste</span><span class="p">(</span><span class="s2">"Total cost: "</span><span class="p">,</span><span class="w"> </span><span class="n">optimal</span><span class="o">$</span><span class="n">objval</span><span class="p">,</span><span class="w"> </span><span class="n">sep</span><span class="o">=</span><span class="s2">""</span><span class="p">))</span><span class="w">

</span><span class="c1"># print(best_solution)</span><span class="w">
</span><span class="c1"># [1] 420 580 161</span><span class="w">

</span><span class="c1"># print(paste("Total cost: ", optimum$objval, sep=""))</span><span class="w">
</span><span class="c1"># "Total cost: 48680"</span><span class="w">
</span></code></pre></div></div> <h2 id="lpsolveapi-solution">lpSolveAPI Solution</h2> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">lpSolveAPI</span><span class="p">)</span><span class="w">

</span><span class="c1">## Cost=30*4P + 40*3P + 80*WoodenBlocks</span><span class="w">

</span><span class="c1">## Set the coefficients of the decision variables -&gt; C</span><span class="w">
</span><span class="n">C</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">30</span><span class="p">,</span><span class="w"> </span><span class="m">40</span><span class="p">,</span><span class="w"> </span><span class="m">80</span><span class="p">)</span><span class="w">

</span><span class="c1"># Create constraint martix B</span><span class="w">
</span><span class="n">A</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">matrix</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">-10</span><span class="p">,</span><span class="w">
              </span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="m">-20</span><span class="p">,</span><span class="w">
              </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">-2</span><span class="p">,</span><span class="w">
              </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="p">),</span><span class="w"> </span><span class="n">nrow</span><span class="o">=</span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="n">byrow</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span><span class="w">


</span><span class="c1"># Right hand side for the constraints</span><span class="w">
</span><span class="n">B</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">500</span><span class="p">,</span><span class="w"> </span><span class="m">200</span><span class="p">,</span><span class="w"> </span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="m">1000</span><span class="p">)</span><span class="w">

</span><span class="c1"># set 4 constraints</span><span class="w">
</span><span class="n">lprec</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">make.lp</span><span class="p">(</span><span class="n">nrow</span><span class="o">=</span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="n">ncol</span><span class="o">=</span><span class="m">3</span><span class="p">)</span><span class="w">
</span><span class="n">lp.control</span><span class="p">(</span><span class="n">lprec</span><span class="p">,</span><span class="w"> </span><span class="n">sense</span><span class="o">=</span><span class="s2">"min"</span><span class="p">)</span><span class="w">

</span><span class="c1"># Set type of decision variables</span><span class="w">
</span><span class="n">set.type</span><span class="p">(</span><span class="n">lprec</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="n">type</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="s2">"integer"</span><span class="p">))</span><span class="w">

</span><span class="c1"># Set objective function coefficients vector C</span><span class="w">
</span><span class="n">set.objfn</span><span class="p">(</span><span class="n">lprec</span><span class="p">,</span><span class="w"> </span><span class="n">C</span><span class="p">)</span><span class="w">

</span><span class="c1"># Add constraints</span><span class="w">
</span><span class="n">add.constraint</span><span class="p">(</span><span class="n">lprec</span><span class="p">,</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="p">],</span><span class="w"> </span><span class="s2">"&lt;="</span><span class="p">,</span><span class="w"> </span><span class="n">B</span><span class="p">[</span><span class="m">1</span><span class="p">])</span><span class="w">
</span><span class="n">add.constraint</span><span class="p">(</span><span class="n">lprec</span><span class="p">,</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="p">],</span><span class="w"> </span><span class="s2">"&lt;="</span><span class="p">,</span><span class="w"> </span><span class="n">B</span><span class="p">[</span><span class="m">2</span><span class="p">])</span><span class="w">
</span><span class="n">add.constraint</span><span class="p">(</span><span class="n">lprec</span><span class="p">,</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="p">],</span><span class="w"> </span><span class="s2">"&lt;="</span><span class="p">,</span><span class="w"> </span><span class="n">B</span><span class="p">[</span><span class="m">3</span><span class="p">])</span><span class="w">
</span><span class="n">add.constraint</span><span class="p">(</span><span class="n">lprec</span><span class="p">,</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="p">],</span><span class="w"> </span><span class="s2">"&gt;="</span><span class="p">,</span><span class="w"> </span><span class="n">B</span><span class="p">[</span><span class="m">4</span><span class="p">])</span><span class="w">

</span><span class="n">lprec</span><span class="w">

</span><span class="c1"># Solve the problem</span><span class="w">
</span><span class="n">solve</span><span class="p">(</span><span class="n">lprec</span><span class="p">)</span><span class="w">

</span><span class="c1"># get the decision variable values</span><span class="w">
</span><span class="n">get.variables</span><span class="p">(</span><span class="n">lprec</span><span class="p">)</span><span class="w">

</span><span class="c1"># get objective function</span><span class="w">
</span><span class="n">get.objective</span><span class="p">(</span><span class="n">lprec</span><span class="p">)</span><span class="w">

</span><span class="c1"># get.variables(lprec)</span><span class="w">
</span><span class="c1"># [1] 420 580 161</span><span class="w">

</span><span class="c1"># get.objective(lprec)</span><span class="w">
</span><span class="c1"># [1] 48680</span><span class="w">
</span></code></pre></div></div>]]></content><author><name></name></author><category term="industrial-engineering"/><category term="linear-programming"/><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">Data Engineering Week 3 - Data Warehouse</title><link href="https://kamalpatell.github.io/blog/2024/data-engineering-data-warehouse-week3/" rel="alternate" type="text/html" title="Data Engineering Week 3 - Data Warehouse"/><published>2024-01-01T12:57:00+00:00</published><updated>2024-01-01T12:57:00+00:00</updated><id>https://kamalpatell.github.io/blog/2024/data-engineering-data-warehouse-week3</id><content type="html" xml:base="https://kamalpatell.github.io/blog/2024/data-engineering-data-warehouse-week3/"><![CDATA[<h3 id="olap-vs-oltp"><strong>OLAP vs OLTP</strong></h3> <p><code class="language-plaintext highlighter-rouge">OLAP (Online Analytical Processing)</code>:</p> <p>Purpose: OLAP is designed for performing multi-dimensional analysis on large datasets quickly and interactively.</p> <p>Data Source: Typically utilizes data from data warehouses, data marts, or centralized data stores.</p> <p>Usage: Ideal for data mining, business intelligence, complex analytical calculations, and business reporting (e.g., financial analysis, budgeting, sales forecasting).</p> <p>Data Model: Based on a multidimensional data model, organizing data into dimensions (e.g., time, geography, product) and measures (e.g., sales revenue, profit margin).</p> <p>Capabilities: Enables users to explore data from different perspectives, perform complex calculations, and analyze data at various levels of granularity.</p> <p>Volume of Data: OLAP has large storage requirements. Think terabytes (TB) and petabytes (PB).</p> <p>Example Applications: OLAP is good for analyzing trends, predicting customer behavior, and identifying profitability.</p> <p><code class="language-plaintext highlighter-rouge">OLTP (Online Transaction Processing)</code>:</p> <p>Purpose: OLTP is designed for managing and processing large volumes of transaction-oriented data in real-time, supporting day-to-day operational tasks.</p> <p>Data Source: OLTP uses real-time and transactional data from a single source.</p> <p>Usage: Critical for operational systems and applications where high availability and fast response times are essential.</p> <p>Data Model: Based on a transactional data model, optimized for recording and processing individual transactions. Data is typically organized into tables.</p> <p>Volume of Data: OLTP has comparatively smaller storage requirements. Think gigabytes (GB).</p> <p>Example Applications:OLTP is good for processing payments, customer data management, and order processing.</p> <p>In summary, OLAP and OLTP serve different purposes in the data management landscape, with OLAP focusing on analytical tasks and decision-making, while OLTP is geared towards supporting real-time transaction processing for day-to-day business operations.</p> <h3 id="key-differences"><strong>Key differences</strong></h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/data/week3/difference-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/data/week3/difference-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/data/week3/difference-1400.webp"/> <img src="/assets/img/blog/data/week3/difference.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> OLAP vs OLTP </div> <h3 id="partitioning-and-clustering-in-bigquery"><strong>Partitioning and Clustering in BigQuery</strong></h3> <p>Partition is a huge advantage so that Big Query doesn’t need to run over the whole table. For example, when most of the queries are based on date and use it as a filter. You can partition a table based on Integer column, or time-unit column, or ingestion time.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/data/week3/partition-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/data/week3/partition-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/data/week3/partition-1400.webp"/> <img src="/assets/img/blog/data/week3/partition.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Partitioning </div> <p>Clustering tables means sort by clustered columns. In this way it can also improve query performance and reduce query costs.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/data/week3/clustering-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/data/week3/clustering-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/data/week3/clustering-1400.webp"/> <img src="/assets/img/blog/data/week3/clustering.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Clustering </div> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- Create a partitioned table from external table</span>
<span class="k">CREATE</span> <span class="k">OR</span> <span class="k">REPLACE</span> <span class="k">TABLE</span> <span class="nv">`dez-de-404011.dezoomcamp.rides_partitioned`</span>
<span class="k">PARTITION</span> <span class="k">BY</span>
 <span class="nb">DATE</span><span class="p">(</span><span class="n">pickup_datetime</span><span class="p">)</span> <span class="k">AS</span>
<span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="nv">`dez-de-404011.dezoomcamp.external_yellow_tripdata`</span><span class="p">;</span>


<span class="c1">-- Creating a partition and cluster table</span>
<span class="k">CREATE</span> <span class="k">OR</span> <span class="k">REPLACE</span> <span class="k">TABLE</span> <span class="nv">`dez-de-404011.dezoomcamp.rides_partitoned_clustered`</span>
<span class="k">PARTITION</span> <span class="k">BY</span> <span class="nb">DATE</span><span class="p">(</span><span class="n">pickup_datetime</span><span class="p">)</span>
<span class="k">CLUSTER</span> <span class="k">BY</span> <span class="n">affiliated_base_number</span> <span class="k">AS</span>
<span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="nv">`dez-de-404011.dezoomcamp.external_yellow_tripdata`</span><span class="p">;</span>
</code></pre></div></div> <h3 id="bigquery-best-practices"><strong>BigQuery Best Practices</strong></h3> <p>Cost reduction</p> <ul> <li>Avoid SELECT *</li> <li>Price your queries before running them</li> <li>Use clustered or partitioned tables</li> <li>Use streaming inserts with caution</li> <li>Materialize query results in stages</li> </ul> <p>Query performance</p> <ul> <li>Filter on partitioned columns</li> <li>Denormalizing data</li> <li>Use nested or repeated columns</li> <li>Use external data sources appropriately</li> <li>Reduce data before using a JOIN</li> <li>Do not treat WITH clauses as prepared statements</li> <li>Avoid oversharding tables</li> <li>Avoid JavaScript user-defined functions</li> <li>Use approximate aggregation functions (HyperLogLog++)</li> <li>Order Last, for query operations to maximize performance</li> <li>Optimize your join patterns</li> <li>As a best practice, place the table with the largest number of rows first, followed by the table with the fewest rows, and then place the remaining tables by decreasing size.</li> </ul>]]></content><author><name></name></author><category term="data"/><category term="data-engineering"/><summary type="html"><![CDATA[Data Warehouse and BigQuery]]></summary></entry><entry><title type="html">Data Engineering Week 2 - Workflow Orchestration</title><link href="https://kamalpatell.github.io/blog/2023/data-engineering-workflow-orchestration-week2/" rel="alternate" type="text/html" title="Data Engineering Week 2 - Workflow Orchestration"/><published>2023-11-13T16:00:00+00:00</published><updated>2023-11-13T16:00:00+00:00</updated><id>https://kamalpatell.github.io/blog/2023/data-engineering-workflow-orchestration-week2</id><content type="html" xml:base="https://kamalpatell.github.io/blog/2023/data-engineering-workflow-orchestration-week2/"><![CDATA[<h3 id="what-is-data-lake"><strong>What is Data Lake</strong></h3> <p>A Data Lake consists of a central repository where any type of data, either structured or unstructured, can be stored. The main idea behind a Data Lake is to ingest and make data available as quickly as possible inside an organization.</p> <p>Several popular data lake solutions available, some of them are:</p> <ol> <li><code class="language-plaintext highlighter-rouge">Amazon S3</code></li> <li><code class="language-plaintext highlighter-rouge">Google Cloud Storage</code></li> <li><code class="language-plaintext highlighter-rouge">Microsoft Azure Data Lake Storage</code></li> <li><code class="language-plaintext highlighter-rouge">Hadoop HDFS</code></li> <li><code class="language-plaintext highlighter-rouge">Snoflake Data Warehouse</code>: It’s a cloud-based data warehouse solution with data lake component.</li> </ol> <h3 id="data-lake-vs-data-warehouse"><strong>Data Lake vs. Data Warehouse</strong></h3> <p>A Data Lake stores a huge amount of data and are normally used for stream processing, machine learning and real time analytics. On the other hand, a Data Warehouse stores structured data for analytics and batch processing.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/data/datalake1-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/data/datalake1-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/data/datalake1-1400.webp"/> <img src="/assets/img/blog/data/datalake1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Data Lake vs. Data Warehouse </div> <h3 id="extract-transform-load-etl-vs-extract-load-transform-elt"><strong>Extract-Transform-Load (ETL) vs. Extract-Load-Transform (ELT)</strong></h3> <p><code class="language-plaintext highlighter-rouge">ETL (Extract, Transform, Load)</code> refers to the traditional approach of extracting data from various sources, transforming the data into the required format, and then loading the data into the warehouse.</p> <p><code class="language-plaintext highlighter-rouge">ELT (Extract, Load, Transform)</code> refers to a newer approach in which the is extracted from various sources and loaded into a data lake first and then transformed and processed for analysis.</p> <p>ETL is usually a Data Warehouse solution, used mainly for small amount of data as a schema-on-write approach. On the other hand, ELT is a Data Lake solution, employed for large amounts of data as a schema-on-read approach.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/data/datalake2-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/data/datalake2-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/data/datalake2-1400.webp"/> <img src="/assets/img/blog/data/datalake2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image: https://vitalflux.com/data-lake-design-principles-best-practices/ </div> <h3 id="introduction-to-data-warehouse"><strong>Introduction to data warehouse</strong></h3> <p>A data warehouse is a central repository of information that can be analyzed to make more informed decisions. Reports, dashboards, and analytics tools are indispensable for business users seeking to derive insights from their data, oversee business performance, and facilitate decision-making. The foundation of these tools lies in data warehouses, which store data efficiently to reduce input and output (I/O) operations, ensuring swift delivery of query results to a multitude of users simultaneously.</p> <p>Popular data warehouse solution available are:</p> <ol> <li> <p><code class="language-plaintext highlighter-rouge">Amazon Redshift</code>: A fully managed, petabyte-scale data warehouse service provided by Amazon Web Services (AWS). Redshift uses columnar storage, parallel query execution, and advanced compression algorithms to provide fast query performance.</p> </li> <li> <p><code class="language-plaintext highlighter-rouge">Google BigQuery</code>: A serverless, highly scalable, and cost-effective cloud data warehouse provided by Google Cloud Platform. BigQuery supports SQL-like queries and provides fast query performance through its columnar storage and massive parallel processing.</p> </li> <li> <p><code class="language-plaintext highlighter-rouge">Microsoft Azure Synapse Analytics (formerly SQL Data Warehouse)</code>: A cloud-based big data analytics service provided by Microsoft Azure. It combines the capabilities of data warehousing and big data analytics, allowing organizations to analyze data at scale.</p> </li> <li> <p><code class="language-plaintext highlighter-rouge">Teradata</code>: A relational database management system for data warehousing and big data analytics provided by Teradata Corporation. Teradata provides a scalable, high-performance platform for storing and analyzing large amounts of structured d</p> </li> </ol> <h3 id="workflow-orchestration"><strong>Workflow Orchestration</strong></h3> <h4 id="what-is-dataflow">What is dataflow</h4> <p>A dataflow defines all extraction and processing steps that the data will be submitted to, also detailing any transformation and intermediate states of the dataset. For example, in an ETL process, a dataset is first extracted (E) from some source (e.g., website, API, etc), then transformed (T) (e.g., dealing with corrupted or missing values, joining datasets, datatype conversion, etc) and finally loaded (L) to some type of storage (e.g., data warehouse).</p> <h4 id="introduction-to-workflow-orchestration">Introduction to workflow orchestration</h4> <p>A workflow orchestration tool allows us to manage and visualize dataflows, while ensuring that they will be run according to a set of predefined rules. A good workflow orchestration tool makes it easy to schedule or execute dataflows remotely, handle faults, integrate with external services, increase reliability.</p> <p>Several tools available for workflow orchestration in data engineering are:</p> <ol> <li> <p><code class="language-plaintext highlighter-rouge">Apache Airflow</code>: An open-source platform for programmatically authoring, scheduling, and monitoring workflows.</p> </li> <li> <p><code class="language-plaintext highlighter-rouge">AWS Glue</code>: A fully managed extract, transform, and load (ETL) service offered by Amazon Web Services (AWS).</p> </li> <li> <p><code class="language-plaintext highlighter-rouge">Prefect</code>: An open-source workflow orchestration tool that provides a simple and flexible interface for building and managing data pipelines.</p> </li> <li> <p><code class="language-plaintext highlighter-rouge">Luigi</code>: An open-source Python module for building complex pipelines and workflows.</p> </li> </ol> <h3 id="introduction-to-prefect-concepts"><strong>Introduction to Prefect concepts</strong></h3> <p>Prefect is an modern management systems for data-intensive workflows. It’s the simplest way to transform any Python function into a unit of work that can be observed and orchestrated.</p> <h3 id="loading-data-into-postgres-using-prefect">Loading data into Postgres using Prefect</h3> <p><strong><code class="language-plaintext highlighter-rouge">Step 1</code></strong></p> <p>Create conda environment to install relevant libraries without affecting base environment.</p> <p>Run <code class="language-plaintext highlighter-rouge">conda create -n zoom python-3.9</code> where zoom is the environment name, you can name anything you want.</p> <p>Then activate the environment by running <code class="language-plaintext highlighter-rouge">conda activate </code></p> <p><strong><code class="language-plaintext highlighter-rouge">Step 2</code></strong></p> <p>Create requirements.txt file which contains all the relevant libraries which we will be using for this lesson.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pandas==1.5.2
prefect==2.7.7
prefect-sqlalchemy==0.2.2
prefect-gcp[cloud_storage]==0.2.4
protobuf==4.21.11
pyarrow==10.0.1
pandas-gbq==0.18.1
psycopg2-binary==2.9.5
sqlalchemy==1.4.46
</code></pre></div></div> <p>Run <code class="language-plaintext highlighter-rouge">pip install -r requirement.txt</code> which will load all the libraries in the zoom environment.</p> <p><strong><code class="language-plaintext highlighter-rouge">Step 3</code></strong></p> <p>Now, lets transform the ingest_data.py file from week 1 into flows and tasks. we can use this concept of task and flow to break the ingest_data python script into multiple tasks and flows which would help us visualize our whole workflow better.</p> <ol> <li>Load the necessary libraries:</li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">os</span>
<span class="kn">import</span> <span class="n">argparse</span>
<span class="kn">from</span> <span class="n">time</span> <span class="kn">import</span> <span class="n">time</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="n">sqlalchemy</span> <span class="kn">import</span> <span class="n">create_engine</span>
<span class="kn">from</span> <span class="n">prefect</span> <span class="kn">import</span> <span class="n">flow</span><span class="p">,</span> <span class="n">task</span>
<span class="kn">from</span> <span class="n">prefect.tasks</span> <span class="kn">import</span> <span class="n">task_input_hash</span>
<span class="kn">from</span> <span class="n">datetime</span> <span class="kn">import</span> <span class="n">timedelta</span>
</code></pre></div></div> <ol> <li>Create an extract function which will help extract data from the given url:</li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@task</span><span class="p">(</span><span class="n">log_prints</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">retries</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">cache_key_fn</span><span class="o">=</span><span class="n">task_input_hash</span><span class="p">,</span> <span class="n">cache_expiration</span><span class="o">=</span><span class="nf">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">extract_data</span><span class="p">(</span><span class="n">csv_url</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">csv_url</span><span class="p">.</span><span class="nf">endswith</span><span class="p">(</span><span class="sh">'</span><span class="s">.csv.gz</span><span class="sh">'</span><span class="p">):</span>
        <span class="n">csv_name</span> <span class="o">=</span> <span class="sh">'</span><span class="s">yellow_tripdata_2021-01.csv.gz</span><span class="sh">'</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">csv_name</span> <span class="o">=</span> <span class="sh">'</span><span class="s">output.csv</span><span class="sh">'</span>

    <span class="n">os</span><span class="p">.</span><span class="nf">system</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">wget </span><span class="si">{</span><span class="n">csv_url</span><span class="si">}</span><span class="s"> -O </span><span class="si">{</span><span class="n">csv_name</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

    <span class="n">df_iter</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="n">csv_name</span><span class="p">,</span> <span class="n">iterator</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">chunksize</span><span class="o">=</span><span class="mi">100000</span><span class="p">)</span>

    <span class="n">df</span> <span class="o">=</span> <span class="nf">next</span><span class="p">(</span><span class="n">df_iter</span><span class="p">)</span>

    <span class="n">df</span><span class="p">.</span><span class="n">tpep_pickup_datetime</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">tpep_pickup_datetime</span><span class="p">)</span>
    <span class="n">df</span><span class="p">.</span><span class="n">tpep_dropoff_datetime</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">tpep_dropoff_datetime</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">df</span>
</code></pre></div></div> <ol> <li>Create a transform function to transform the data:</li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@task</span><span class="p">(</span><span class="n">log_prints</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">transform_data</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">pre: missing passenger count: </span><span class="si">{</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">passenger_count</span><span class="sh">'</span><span class="p">].</span><span class="nf">isin</span><span class="p">([</span><span class="mi">0</span><span class="p">]).</span><span class="nf">sum</span><span class="p">()</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">passenger_count</span><span class="sh">'</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">]</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">post: missing passenger count: </span><span class="si">{</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">passenger_count</span><span class="sh">'</span><span class="p">].</span><span class="nf">isin</span><span class="p">([</span><span class="mi">0</span><span class="p">]).</span><span class="nf">sum</span><span class="p">()</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">df</span>
</code></pre></div></div> <ol> <li>Next we create load function(ingest_data) to load the data:</li> </ol> <p>Here we use a concepts of block to store configuration and provide an interface of interacting with external systems.</p> <p>In our ingest_data.py, instead of hard coding all the input credentials(url, user, passwords) as shown in below commented code we can create a block which can store the credentials and can be called directly.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/data//week2/block1-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/data//week2/block1-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/data//week2/block1-1400.webp"/> <img src="/assets/img/blog/data//week2/block1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/data/week2/block2-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/data/week2/block2-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/data/week2/block2-1400.webp"/> <img src="/assets/img/blog/data/week2/block2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/data/week2/block3-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/data/week2/block3-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/data/week2/block3-1400.webp"/> <img src="/assets/img/blog/data/week2/block3.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@task</span><span class="p">(</span><span class="n">log_prints</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">retries</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ingest_data</span><span class="p">(</span><span class="n">table_name</span><span class="p">,</span> <span class="n">df</span><span class="p">):</span>

    <span class="n">connection_block</span> <span class="o">=</span> <span class="n">SqlAlchemyConnector</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">'</span><span class="s">postgres-connector</span><span class="sh">'</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">connection_block</span><span class="p">.</span><span class="nf">get_connection</span><span class="p">(</span><span class="n">begin</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> <span class="k">as</span> <span class="n">engine</span><span class="p">:</span>
        <span class="n">df</span><span class="p">.</span><span class="nf">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">to_sql</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">table_name</span><span class="p">,</span> <span class="n">con</span><span class="o">=</span><span class="n">engine</span><span class="p">,</span> <span class="n">if_exists</span><span class="o">=</span><span class="sh">'</span><span class="s">replace</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">df</span><span class="p">.</span><span class="nf">to_sql</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">table_name</span><span class="p">,</span> <span class="n">con</span><span class="o">=</span><span class="n">engine</span><span class="p">,</span> <span class="n">if_exists</span><span class="o">=</span><span class="sh">'</span><span class="s">replace</span><span class="sh">'</span><span class="p">)</span>

        <span class="c1"># postgres_url = f'postgresql://{user}:{password}@{host}:{port}/{db}'
</span>        <span class="c1"># engine = create_engine(postgres_url)
</span>
        <span class="c1"># df.head(n=0).to_sql(name=table_name, con=engine if_exists='replace')
</span>        <span class="c1"># df.to_sql(name=table_name, con=engine, if_exists='append')
</span></code></pre></div></div> <ol> <li>Finally, we create a main function which will help us run all of these functions</li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@flow</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">Ingest Flow</span><span class="sh">"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="n">table_name</span><span class="p">:</span><span class="nb">str</span><span class="p">):</span>
    <span class="c1"># user = "root"
</span>    <span class="c1"># password = "root"
</span>    <span class="c1"># host = "localhost"
</span>    <span class="c1"># port = "5432"
</span>    <span class="c1"># db = "ny_taxi"
</span>    <span class="n">csv_url</span> <span class="o">=</span> <span class="sh">"</span><span class="s">https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2021-01.csv.gz</span><span class="sh">"</span>

    <span class="nf">log_subflow</span><span class="p">(</span><span class="n">table_name</span><span class="p">)</span>
    <span class="n">raw_data</span> <span class="o">=</span> <span class="nf">extract_data</span><span class="p">(</span><span class="n">csv_url</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="nf">transform_data</span><span class="p">(</span><span class="n">raw_data</span><span class="p">)</span>
    <span class="nf">ingest_data</span><span class="p">(</span><span class="n">table_name</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="sh">'</span><span class="s">__main__</span><span class="sh">'</span><span class="p">:</span>
    <span class="nf">main</span><span class="p">(</span><span class="sh">"</span><span class="s">yellow_taxi_trips</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p><strong><code class="language-plaintext highlighter-rouge">Step 4</code></strong></p> <p>Save this file as <code class="language-plaintext highlighter-rouge">ingest_data_flow.py</code> and run the file through GitBash by using the command <code class="language-plaintext highlighter-rouge">python ingest_data_flow.py</code></p> <p>This should successfully load the data into postgres. But since we have only given the first chunk, it wont load the full dataset. As you can see below, since we set log_prints as True, we can clearly see the logs for each function. Also as you can see, the number of records is ~100,000 as only the first chunk is loaded. [185 records with 0 passenger count was removed. Check the transform function in the code above]</p> <h3 id="etl-to-gcp">ETL to GCP</h3> <p><strong><code class="language-plaintext highlighter-rouge">Step 1</code></strong>: Register the block with command</p> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>prefect block register <span class="nt">-m</span> prefect_gcp

</code></pre></div></div> <p><strong><code class="language-plaintext highlighter-rouge">Step 2</code></strong> : Create a google cloud storage bucket block connector</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/data/week2/gcs1-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/data/week2/gcs1-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/data/week2/gcs1-1400.webp"/> <img src="/assets/img/blog/data/week2/gcs1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><strong><code class="language-plaintext highlighter-rouge">Step 3</code></strong>: Add GCS credential</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/data/week2/gcs2-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/data/week2/gcs2-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/data/week2/gcs2-1400.webp"/> <img src="/assets/img/blog/data/week2/gcs2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><strong><code class="language-plaintext highlighter-rouge">Step 4</code></strong> : ETL from gcs to bq</p> <p>To write to gsc</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@task</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">write_gcs</span><span class="p">(</span><span class="n">path</span><span class="p">:</span><span class="n">Path</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">Upload the parquet file to gcs</span><span class="sh">"""</span>

    <span class="n">gcp_storage_block</span> <span class="o">=</span> <span class="n">GcsBucket</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">"</span><span class="s">zoom-gcs</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">gcp_storage_block</span><span class="p">.</span><span class="nf">upload_from_path</span><span class="p">(</span><span class="n">from_path</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="sh">"</span><span class="p">,</span> <span class="n">to_path</span><span class="o">=</span><span class="n">path</span><span class="p">)</span>
    <span class="k">return</span>
</code></pre></div></div> <p>To load data to gcs we follow the same step as from loading to postgres and adjusted our code when necessary.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="kn">from</span> <span class="n">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="n">prefect</span> <span class="kn">import</span> <span class="n">flow</span><span class="p">,</span> <span class="n">task</span>
<span class="kn">from</span> <span class="n">prefect_gcp.cloud_storage</span> <span class="kn">import</span> <span class="n">GcsBucket</span>
<span class="kn">from</span> <span class="n">random</span> <span class="kn">import</span> <span class="n">randint</span>
<span class="kn">from</span> <span class="n">prefect_gcp.cloud_storage</span> <span class="kn">import</span> <span class="n">GcsBucket</span>

<span class="nd">@task</span><span class="p">(</span><span class="n">retries</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">fetch</span><span class="p">(</span><span class="n">dataset_url</span><span class="p">:</span><span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">Read taxi data from web into pandas DataFrame</span><span class="sh">"""</span>

    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="n">dataset_url</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">df</span>

<span class="nd">@task</span><span class="p">(</span><span class="n">log_prints</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">clean</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">Fix dtypes issues</span><span class="sh">"""</span>
    <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">tpep_pickup_datetime</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">tpep_pickup_datetime</span><span class="sh">'</span><span class="p">])</span>
    <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">tpep_dropoff_datetime</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">tpep_dropoff_datetime</span><span class="sh">'</span><span class="p">])</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="nf">head</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">columns: </span><span class="si">{</span><span class="n">df</span><span class="p">.</span><span class="n">dtypes</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">rows: </span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">df</span>

<span class="nd">@task</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">write_local</span><span class="p">(</span><span class="n">df</span><span class="p">:</span><span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">color</span><span class="p">:</span><span class="nb">str</span><span class="p">,</span> <span class="n">dataset_file</span><span class="p">:</span><span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Path</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">Write Dataframe out as parquet file</span><span class="sh">"""</span>

    <span class="n">path</span> <span class="o">=</span> <span class="nc">Path</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">../data/</span><span class="si">{</span><span class="n">color</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">dataset_file</span><span class="si">}</span><span class="s">.parquet</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">df</span><span class="p">.</span><span class="nf">to_parquet</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="sh">"</span><span class="s">gzip</span><span class="sh">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">path</span>


<span class="nd">@task</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">write_gcs</span><span class="p">(</span><span class="n">path</span><span class="p">:</span><span class="n">Path</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">Upload the parquet file to gcs</span><span class="sh">"""</span>

    <span class="n">gcp_storage_block</span> <span class="o">=</span> <span class="n">GcsBucket</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">"</span><span class="s">zoom-gcs</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">gcp_storage_block</span><span class="p">.</span><span class="nf">upload_from_path</span><span class="p">(</span><span class="n">from_path</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="sh">"</span><span class="p">,</span> <span class="n">to_path</span><span class="o">=</span><span class="n">path</span><span class="p">)</span>
    <span class="k">return</span>

<span class="nd">@flow</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">etl_web_to_gcs</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">The Main ETL Function</span><span class="sh">"""</span>
    <span class="n">color</span> <span class="o">=</span> <span class="sh">"</span><span class="s">yellow</span><span class="sh">"</span>
    <span class="n">year</span> <span class="o">=</span> <span class="mi">2021</span>
    <span class="n">month</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">dataset_file</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">color</span><span class="si">}</span><span class="s">_tripdata_</span><span class="si">{</span><span class="n">year</span><span class="si">}</span><span class="s">-</span><span class="si">{</span><span class="n">month</span><span class="si">:</span><span class="mi">02</span><span class="si">}</span><span class="sh">"</span>
    <span class="n">dataset_url</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">https://github.com/DataTalksClub/nyc-tlc-data/releases/download/</span><span class="si">{</span><span class="n">color</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">dataset_file</span><span class="si">}</span><span class="s">.csv.gz</span><span class="sh">"</span>

    <span class="n">df</span> <span class="o">=</span> <span class="nf">fetch</span><span class="p">(</span><span class="n">dataset_url</span><span class="p">)</span>
    <span class="n">df_clean</span> <span class="o">=</span> <span class="nf">clean</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
    <span class="n">path</span> <span class="o">=</span> <span class="nf">write_local</span><span class="p">(</span><span class="n">df_clean</span><span class="p">,</span> <span class="n">color</span><span class="p">,</span> <span class="n">dataset_file</span><span class="p">)</span>
    <span class="nf">write_gcs</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="sh">'</span><span class="s">__main__</span><span class="sh">'</span><span class="p">:</span>
    <span class="nf">etl_web_to_gcs</span><span class="p">()</span>

</code></pre></div></div> <h3 id="prefect-deployment">Prefect Deployment</h3> <p>Prefect is a workflow management system designed to help data engineers and data scientists automate, schedule, and monitor data workflows. Deploying a Prefect workflow involves setting it up to run in a production environment, allowing it to be executed on a schedule or triggered by external events.</p> <h4 id="using-prefect-cli">Using Prefect CLI</h4> <p>There are two methods to deploy the flow: CLI or python file.</p> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>prefect deployment build ./parameterized_flow.py:etl_parent_flow <span class="nt">-n</span> <span class="s2">"Parameterized ETL"</span>
</code></pre></div></div> <ul> <li> <p>Command: <code class="language-plaintext highlighter-rouge">prefect deployment build</code>: This Prefect CLI command is used to prepare the settings for a deployment. The build command likely indicates that it’s configuring and setting up the deployment environment.</p> </li> <li> <p>./parameterized_flow.py:etl_parent_flow: This part of the command specifies the location of the Prefect flow script file and the name of the entrypoint flow function. In this case, the script is parameterized_flow.py, and the entrypoint flow function is etl_parent_flow. The format is file_path:entrypoint_function.</p> </li> <li> <p>-n log-simple: This part of the command uses the -n flag to specify a name for the deployment. In this case, the name provided is log-simple. Naming deployments can be helpful for identification and management.</p> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/data/week2/deploy3-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/data/week2/deploy3-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/data/week2/deploy3-1400.webp"/> <img src="/assets/img/blog/data/week2/deploy3.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>As you can see from the output that prefect deployment build command generates a YAML file defining a Prefect deployment. It includes workflow details (file, object name), deployment info (name, version, environment), configuration values, and metadata (creation timestamp, Prefect version). This YAML file is input for deploying or updating workflows via Prefect CLI or API, allowing easy management and modification of deployments.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/data/week2/deploy1-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/data/week2/deploy1-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/data/week2/deploy1-1400.webp"/> <img src="/assets/img/blog/data/week2/deploy1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/data/week2/deploy2-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/data/week2/deploy2-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/data/week2/deploy2-1400.webp"/> <img src="/assets/img/blog/data/week2/deploy2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Before deploying, we can edit some of the work queue in the YAML file to add more details like Parameters, schedules, etc.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/data/week2/deploy4-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/data/week2/deploy4-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/data/week2/deploy4-1400.webp"/> <img src="/assets/img/blog/data/week2/deploy4.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Then we can use the following command to apply the deployment</p> <p><code class="language-plaintext highlighter-rouge">prefect deployment apply etl_parent_flow-deployment.yaml</code></p> <p>This action involves deploying the workflow described in the YAML file to the target environment. The specific target environment could be either a Prefect Cloud instance or a Prefect Server, depending on the configuration details specified within the YAML file.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/data/week2/deploy5-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/data/week2/deploy5-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/data/week2/deploy5-1400.webp"/> <img src="/assets/img/blog/data/week2/deploy5.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>If you navigate to the prefect UI, you can see that the deployment has been created:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/data/week2/deploy6-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/data/week2/deploy6-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/data/week2/deploy6-1400.webp"/> <img src="/assets/img/blog/data/week2/deploy6.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>There are 2 types of run -</p> <p><code class="language-plaintext highlighter-rouge">Quick Run</code> - Simpler way to run a workflow, providing only a limited set of options. The inputs and environment variables are pre-configured based on the default values specified in the workflow, and you cannot specify additional options or modify the inputs and environment variables.</p> <p><code class="language-plaintext highlighter-rouge">Custom Run</code> - Allows you to manually specify the input parameters and environment variables for a run, and provides greater control over the execution of the workflow. You can also specify advanced run options, such as the run schedule and how long to retain logs and artifacts.</p> <p><strong>Agents and Work Queues</strong></p> <p>In Prefect, two key concepts for executing workflows in a distributed manner are “Work Queues” and “Agents.”</p> <p><code class="language-plaintext highlighter-rouge">Work Queues</code>:</p> <ul> <li>A Work Queue is a data structure that serves as a buffer between Prefect Core and the agents.</li> <li>It holds tasks that are ready to be executed, allowing Prefect Core to manage the tasks while agents pull and execute them.</li> <li>Work Queues facilitate a smooth flow of tasks between the workflow manager and the agents.</li> </ul> <p><code class="language-plaintext highlighter-rouge">Agents</code>:</p> <ul> <li>An Agent is a software component responsible for pulling tasks from the Work Queue and executing them.</li> <li>Agents can operate on various platforms, such as local machines, cloud infrastructure, or containers.</li> <li>They play a crucial role in the distributed execution of workflows.</li> <li>Agents can be deployed on a single node or in a cluster, working collaboratively to process tasks from the Work Queue.</li> <li>They contribute to the parallel and scalable execution of tasks by efficiently distributing the workload.</li> </ul> <p>Our Example</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/data/week2/deploy7-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/data/week2/deploy7-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/data/week2/deploy7-1400.webp"/> <img src="/assets/img/blog/data/week2/deploy7.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>We can then call the agent to pick up the workflow and execute it by using the following command -</p> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>prefect agent start <span class="nt">--work-queue</span> <span class="s2">"default"</span>
</code></pre></div></div> <h3 id="docker-infrastructure">Docker Infrastructure</h3> <ol> <li>Create docker image</li> </ol> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/data/week2/docker1-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/data/week2/docker1-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/data/week2/docker1-1400.webp"/> <img src="/assets/img/blog/data/week2/docker1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <ol> <li>Run the command <code class="language-plaintext highlighter-rouge">docker build -t &lt;hub-user&gt;/&lt;repo-name&gt;[:&lt;tag&gt;] .</code> -&gt; <code class="language-plaintext highlighter-rouge">docker image build -t k2ki/prefect:zoom .</code></li> </ol> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/data/week2/docker2-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/data/week2/docker2-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/data/week2/docker2-1400.webp"/> <img src="/assets/img/blog/data/week2/docker2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <ol> <li> <p>push it into the hub so that it can be used <code class="language-plaintext highlighter-rouge">docker image push k2ki/prefect:zoom</code></p> </li> <li> <p>Create docker block in Prefect UI. Edit the field accordingly.</p> </li> </ol> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/data/week2/docker3-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/data/week2/docker3-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/data/week2/docker3-1400.webp"/> <img src="/assets/img/blog/data/week2/docker3.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h4 id="prefect-deployment-1">prefect deployment</h4> <ol> <li>write the python code</li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">prefect.deployments</span> <span class="kn">import</span> <span class="n">Deployment</span>
<span class="kn">from</span> <span class="n">prefect.infrastructure.container</span> <span class="kn">import</span> <span class="n">DockerContainer</span>
<span class="kn">from</span> <span class="n">parameterized_flow1</span> <span class="kn">import</span> <span class="n">etl_parent_flow</span>

<span class="n">docker_block</span> <span class="o">=</span> <span class="n">DockerContainer</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">"</span><span class="s">zoom</span><span class="sh">"</span><span class="p">)</span>

<span class="n">docker_dep</span> <span class="o">=</span> <span class="n">Deployment</span><span class="p">.</span><span class="nf">build_from_flow</span><span class="p">(</span><span class="n">flow</span><span class="o">=</span><span class="n">etl_parent_flow</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">docker-flow</span><span class="sh">"</span><span class="p">,</span> <span class="n">infrastructure</span><span class="o">=</span><span class="n">docker_block</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="sh">"</span><span class="s">__main__</span><span class="sh">"</span><span class="p">:</span>
    <span class="n">docker_dep</span><span class="p">.</span><span class="nf">apply</span><span class="p">()</span>
</code></pre></div></div> <ol> <li>Execute the code</li> </ol> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python docker_deploy.py
</code></pre></div></div> <ol> <li>Verify in prefect UI</li> </ol> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/data/week2/docker4-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/data/week2/docker4-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/data/week2/docker4-1400.webp"/> <img src="/assets/img/blog/data/week2/docker4.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <ol> <li>Start an agent using <code class="language-plaintext highlighter-rouge">prefect agent start -q default</code></li> </ol> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/data/week2/docker5-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/data/week2/docker5-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/data/week2/docker5-1400.webp"/> <img src="/assets/img/blog/data/week2/docker5.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <ol> <li>Run the docker flow we created from CLI by running the command <code class="language-plaintext highlighter-rouge">prefect deployment run etl-parent-flow/docker-flow</code></li> </ol> <p>This should complete the workflow process load the data into GCS.</p>]]></content><author><name></name></author><category term="data"/><category term="data-engineering"/><summary type="html"><![CDATA[Workflow orchestration with prefect]]></summary></entry><entry><title type="html">Data Engineering Week 1 - Docker and Postgresql</title><link href="https://kamalpatell.github.io/blog/2023/data-engineering-zoomcamp-week1/" rel="alternate" type="text/html" title="Data Engineering Week 1 - Docker and Postgresql"/><published>2023-11-07T12:57:00+00:00</published><updated>2023-11-07T12:57:00+00:00</updated><id>https://kamalpatell.github.io/blog/2023/data-engineering-zoomcamp-week1</id><content type="html" xml:base="https://kamalpatell.github.io/blog/2023/data-engineering-zoomcamp-week1/"><![CDATA[<p>The Data Engineering Zoomcamp is a 7 week data engineering course. It offers free instruction on the most widely used technologies and tools in data engineering and the cloud. During week 1, participants learns to build a data pipeline and retrieve and ingest data using Docker, Postgres, Docker-compose, Terraform and Google Cloud. Key topics covered in week 1 include: Docker, Postgres, Docker-compose, Terraform, Google Cloud, and Google VM.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/data/de-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/data/de-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/data/de-1400.webp"/> <img src="/assets/img/blog/data/de.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Data Engineering Pipeline </div> <h3 id="docker-and-postgres">Docker and Postgres</h3> <p><strong>Introduction of the Docker</strong></p> <p>Docker is an open-source platform that allows developer to easily create, deploy and run applications in containers. Containers are lightweight portable and self suffcient environments that allow applications to run consistently across different environment.</p> <p><strong>Introduction of Postgres</strong></p> <p>Postgres is a versatile database that is designed for transactional purposes rather than analytics. Despite this, it is powerful and sometimes employed as a data warehouse solution.</p> <h3 id="docker-command">Docker command</h3> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker run hello-world

<span class="c"># -it: run iterative mode</span>

docker run <span class="nt">-it</span> ubuntu bash <span class="se">\</span>
docker run <span class="nt">-it</span> python:3.9 <span class="se">\</span>
docker run <span class="nt">-it</span> <span class="nt">--entrypoint</span><span class="o">=</span>bash python:3.9<span class="sb">`</span>

<span class="c"># build an image called taxi-ingest:v001</span>

docker build <span class="nt">-t</span> taxi-ingest:v001 <span class="nb">.</span>
docker run <span class="nt">-it</span> <span class="nb">test</span>:pandas<span class="sb">`</span>
</code></pre></div></div> <p><strong>Ingesting data into the database</strong></p> <p>Once you have created this Dockerfile, you can build the image by running the command docker build -t mypostgres . and then run it with docker run -p 5432:5432 mypostgres. This will start the container and map port 5432 on the host to port 5432 in the container. Dockerfile</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">FROM</span> <span class="n">python</span><span class="p">:</span><span class="mf">3.9</span><span class="p">.</span><span class="mi">1</span>

<span class="n">RUN</span> <span class="n">apt</span><span class="o">-</span><span class="n">get</span> <span class="n">install</span> <span class="n">wget</span>
<span class="n">RUN</span> <span class="n">pip</span> <span class="n">install</span> <span class="n">pandas</span> <span class="n">sqlalchemy</span> <span class="n">psycopg2</span>

<span class="n">WORKDIR</span> <span class="o">/</span><span class="n">app</span>
<span class="n">COPY</span> <span class="n">ingest_data</span><span class="p">.</span><span class="n">py</span> <span class="n">ingest_data</span><span class="p">.</span><span class="n">py</span>

<span class="n">ENTRYPOINT</span> <span class="p">[</span> <span class="sh">"</span><span class="s">python</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">ingest_data.py</span><span class="sh">"</span> <span class="p">]</span>

</code></pre></div></div> <p>By running the above commands, your dataset will be loaded and ready for use in the postgres container.</p> <p><strong>Running Postgres locally with Docker</strong></p> <p><code class="language-plaintext highlighter-rouge">docker run -it \ -e POSTGRES_USER="root" \ -e POSTGRES_PASSWORD="root" \ -e POSTGRES_DB="ny_taxi" \ -v "$(pwd)/ny_taxi_postgres_data:/var/lib/postgresql/data"\ -p 5432:5432 \ postgres:13</code></p> <p>To interact with Postgres in command line we can install <a href="https://www.pgcli.com/install">pgcli</a>.</p> <p><strong>Install pgcli with pip</strong></p> <p><code class="language-plaintext highlighter-rouge">pip install pgcli</code></p> <p><strong>Connect with the postgres</strong></p> <p><code class="language-plaintext highlighter-rouge">pgcli -h localhost -p 5432 -u root -d ny_taxi</code></p> <p><strong>Check with tables</strong></p> <p><code class="language-plaintext highlighter-rouge">\dt</code></p> <p><strong>Jupyter Notebook</strong></p> <p>we will import yellow trip taxi data from nyc taxi website and read the data as iteration in chunks to insert into the sql database.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># read the data with pandas
</span><span class="n">df_iter</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">./yellow_tripdata_2021-07.csv</span><span class="sh">'</span><span class="p">,</span> <span class="n">iterator</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">chunksize</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># used next(iter object) to iterate through chunks
</span><span class="n">df</span> <span class="o">=</span> <span class="nf">next</span><span class="p">(</span><span class="n">df_iter</span><span class="p">)</span>

<span class="c1"># convert pick and drop time into datetime objects
</span><span class="n">df</span><span class="p">.</span><span class="n">tpep_pickup_datetime</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">tpep_pickup_datetime</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="n">tpep_dropoff_datetime</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">tpep_dropoff_datetime</span><span class="p">)</span>

<span class="c1"># insert to sql
</span><span class="o">%</span><span class="n">time</span> <span class="n">df</span><span class="p">.</span><span class="nf">to_sql</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">yellow_taxi_data</span><span class="sh">'</span><span class="p">,</span> <span class="n">con</span><span class="o">=</span><span class="n">engine</span><span class="p">,</span> <span class="n">if_exists</span><span class="o">=</span><span class="sh">'</span><span class="s">replace</span><span class="sh">'</span><span class="p">)</span>

<span class="kn">from</span> <span class="n">time</span> <span class="kn">import</span> <span class="n">time</span>
<span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
    <span class="n">t_start</span> <span class="o">=</span> <span class="nf">time</span><span class="p">()</span>

    <span class="n">df</span> <span class="o">=</span> <span class="nf">next</span><span class="p">(</span><span class="n">df_iter</span><span class="p">)</span>

    <span class="n">df</span><span class="p">.</span><span class="n">tpep_pickup_datetime</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">tpep_pickup_datetime</span><span class="p">)</span>
    <span class="n">df</span><span class="p">.</span><span class="n">tpep_dropoff_datetime</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">tpep_dropoff_datetime</span><span class="p">)</span>

    <span class="n">df</span><span class="p">.</span><span class="nf">to_sql</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">yellow_taxi_data</span><span class="sh">'</span><span class="p">,</span> <span class="n">con</span><span class="o">=</span><span class="n">engine</span><span class="p">,</span> <span class="n">if_exists</span><span class="o">=</span><span class="sh">'</span><span class="s">append</span><span class="sh">'</span><span class="p">)</span>

    <span class="n">t_end</span> <span class="o">=</span> <span class="nf">time</span><span class="p">()</span>

    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">inserted another chunk..., took %.3f second</span><span class="sh">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">t_end</span> <span class="o">-</span> <span class="n">t_start</span><span class="p">))</span>
</code></pre></div></div> <p><strong>pgAdmin</strong></p> <ul> <li>It’s not convenient to use pgcli for data exploration and querying. Instead, we will use <a href="https://www.pgadmin.org/">pgAdmin</a>, the standard graphical tool for postgres. We can run it with docker. However, this docker container can’t access the postgres container. We need to link them.</li> </ul> <p><code class="language-plaintext highlighter-rouge">docker run -it \ -e PGADMIN_DEFAULT_EMAIL="admin@admin.com" \ -e PGADMIN_DEFAULT_PASSWORD="root" \ -p 8080:80 \ dpage/pgadmin4</code></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/data/pgadmin-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/data/pgadmin-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/data/pgadmin-1400.webp"/> <img src="/assets/img/blog/data/pgadmin.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> pgadmin dashboard </div> <p><strong>Docker Network</strong></p> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># To link the database with pgadmin</span>
<span class="c"># Connect a container to a network</span>
docker network create pgnetwork

docker run <span class="nt">-it</span> <span class="se">\</span>
  <span class="nt">-e</span> <span class="nv">POSTGRES_USER</span><span class="o">=</span><span class="s2">"root"</span> <span class="se">\</span>
  <span class="nt">-e</span> <span class="nv">POSTGRES_PASSWORD</span><span class="o">=</span><span class="s2">"root"</span> <span class="se">\</span>
  <span class="nt">-e</span> <span class="nv">POSTGRES_DB</span><span class="o">=</span><span class="s2">"ny_taxi"</span> <span class="se">\</span>
  <span class="nt">-v</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">pwd</span><span class="si">)</span><span class="s2">/ny_taxi_postgres_data:/var/lib/postgresql/data"</span><span class="se">\</span>
  <span class="nt">-p</span> 5432:5432 <span class="se">\</span>
  <span class="nt">--name</span> pgdatabase <span class="se">\</span>
  <span class="nt">--network</span> pgnetwork <span class="se">\</span>
  postgres:13

docker run <span class="nt">-it</span> <span class="se">\</span>
  <span class="nt">-e</span> <span class="nv">PGADMIN_DEFAULT_EMAIL</span><span class="o">=</span><span class="s2">"admin@admin.com"</span> <span class="se">\</span>
  <span class="nt">-e</span> <span class="nv">PGADMIN_DEFAULT_PASSWORD</span><span class="o">=</span><span class="s2">"root"</span> <span class="se">\</span>
  <span class="nt">-p</span> 8080:80 <span class="se">\</span>
  <span class="nt">--name</span> pgadmin <span class="se">\</span>
  <span class="nt">--network</span> pgnetwork <span class="se">\</span>
  dpage/pgadmin4

<span class="c"># Ingest data</span>
docker run <span class="nt">-it</span> <span class="se">\</span>
    <span class="nt">--network</span><span class="o">=</span>pgnetwork <span class="se">\</span>
    taxi-ingest:v001 <span class="se">\</span>
        <span class="nt">--user</span><span class="o">=</span>root <span class="se">\</span>
        <span class="nt">--password</span><span class="o">=</span>root <span class="se">\</span>
        <span class="nt">--host</span><span class="o">=</span>pgdatabase <span class="se">\</span>
        <span class="nt">--port</span><span class="o">=</span>5432 <span class="se">\</span>
        <span class="nt">--db</span><span class="o">=</span>ny_taxi <span class="se">\</span>
        <span class="nt">--table_name</span><span class="o">=</span>green_taxi_trips <span class="se">\</span>
        <span class="nt">--url</span><span class="o">=</span><span class="k">${</span><span class="nv">URL</span><span class="k">}</span>

</code></pre></div></div> <p>It works, but we need to keep two terminal tabs running, manually create a network - and a bunch of other things. Let’s use docker compose that will take care of that.</p> <p><strong>Docker-compose</strong></p> <p>Docker Compose is a powerful tool that makes it easy to define and run multi-container Docker applications, simplifying the process of development, testing, and deployment. It allows developers to define all the services and dependencies of an application in a single file, and then start, stop, and manage those services with simple commands. Docker Compose also allows developers to define networks and volumes that can be shared between services. The docker-compose.yml file is a YAML file that defines the services, networks, and volumes needed for the application.</p> <p><strong>Start the application in “detached” mode: the containers run in the background and the terminal is free for other commands.</strong> <code class="language-plaintext highlighter-rouge">docker-compose up -d</code></p> <p><strong>Stop and remove the containers</strong> <code class="language-plaintext highlighter-rouge">docker-compose down</code></p> <p>docker-compose.yml file</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">services</span><span class="pi">:</span>
  <span class="na">pgdatabase</span><span class="pi">:</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">postgres:13</span>
    <span class="na">environment</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">POSTGRES_USER=root</span>
      <span class="pi">-</span> <span class="s">POSTGRES_PASSWORD=root</span>
      <span class="pi">-</span> <span class="s">POSTGRES_DB=ny_taxi</span>
    <span class="na">volumes</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">./ny_taxi_postgres_data:/var/lib/postgresql/data:rw"</span>
    <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">5432:5432"</span>
  <span class="na">pgadmin</span><span class="pi">:</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">dpage/pgadmin4</span>
    <span class="na">environment</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">PGADMIN_DEFAULT_EMAIL=admin@admin.com</span>
      <span class="pi">-</span> <span class="s">PGADMIN_DEFAULT_PASSWORD=root</span>
    <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">8080:80"</span>
</code></pre></div></div> <h3 id="terraform--google-cloud-platform">Terraform + Google Cloud Platform</h3> <p><strong>Terraform</strong></p> <p><a href="https://www.terraform.io/">Terraform</a> is an open-source infrastructure as code software tool that enables you to safely and predictably create, change, and improve infrastructure. First of all, follow the instruction to <a href="https://developer.hashicorp.com/terraform/downloads?ajs_aid=1ddc0b9c-f34a-4de4-8a92-f83ddc38f58b&amp;product_intent=terraform">install Terraform</a>.</p> <p>Command:</p> <ol> <li><code class="language-plaintext highlighter-rouge">terraform init</code>: <ul> <li>Initializes &amp; configures the backend, installs plugins/providers, &amp; checks out an existing configuration from a version control</li> </ul> </li> <li><code class="language-plaintext highlighter-rouge">terraform plan</code>: <ul> <li>Matches/previews local changes against a remote state, and proposes an Execution Plan.</li> </ul> </li> <li><code class="language-plaintext highlighter-rouge">terraform apply</code>: <ul> <li>Asks for approval to the proposed plan, and applies changes to cloud</li> </ul> </li> <li><code class="language-plaintext highlighter-rouge">terraform destroy</code> <ul> <li>Removes your stack from the Cloud</li> </ul> </li> </ol> <p><strong>Google Account</strong></p> <p>Step 1: Create a new google account and get free 300€.</p> <p>Step 2: Create a new project.</p> <p>Step 3: Create a service account</p> <ul> <li>Assign the role as Viewer.</li> <li>Create and download the key.</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/data/gcp-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/data/gcp-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/data/gcp-1400.webp"/> <img src="/assets/img/blog/data/gcp.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Google Cloud Platform </div> <p><strong>Install Google SDK</strong></p> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>~ ./google-cloud-sdk/install.sh
<span class="c">#Welcome to the Google Cloud CLI!</span>

~ gcloud init

<span class="nb">export </span><span class="nv">GOOGLE_APPLICATION_CREDENTIALS</span><span class="o">=</span><span class="s2">"&lt;path/to/your/service-account-authkeys&gt;.json"</span>

<span class="c"># Refresh token/session, and verify authentication</span>
gcloud auth application-default login
</code></pre></div></div>]]></content><author><name></name></author><category term="data"/><category term="data-engineering"/><summary type="html"><![CDATA[Introduction to data engineering by Alexey Grigorev]]></summary></entry><entry><title type="html">Travel Paths Using A* In FlexSim</title><link href="https://kamalpatell.github.io/blog/2023/flexsim-astar/" rel="alternate" type="text/html" title="Travel Paths Using A* In FlexSim"/><published>2023-07-31T22:00:00+00:00</published><updated>2023-07-31T22:00:00+00:00</updated><id>https://kamalpatell.github.io/blog/2023/flexsim-astar</id><content type="html" xml:base="https://kamalpatell.github.io/blog/2023/flexsim-astar/"><![CDATA[<p>In Flexsim task executer, such as operators and transporters, travel in straight path between points, as it provides computational efficiency. However, this simplistic approach can lead to unrealistic scenario since real world operators cannot move through machines, conveyors, or other obstacles.</p> <p>The use of straight-line paths not only hampers the visual realism of the simulation but also affects the accuracy of estimated system performance. To improve the realism and reliability of simulations, it is essential to implement object-avoidance algorithms and movement constraints that align with real-world constraints faced by operators and transporters.</p> <h3 id="a-star-algorithm">A-Star Algorithm</h3> <p>This is a popular path-finding algorithm that is commonly used in computer science and mathematics. It is specifically designed to find the shortest path from starting point to a goal point in a graph or a grid while considering the cost to reach the goal.</p> <p>Its quite easy to implement A* algorithm in Flexsim. The object associated with A* algorithm are in the section of the object library below the visual section.</p> <p>As shown in the figure below, create a simple model with operator transporting an item between Source and Sink. In between I have added some objects such as queue and processors that are not connected to any other resources.</p> <ol> <li>Drag out a source, sink, operator and processor machines as show in the below figure.</li> <li>Connect source to sink using A-connect.</li> <li>Click source and in the properties section, under output click use transport.</li> <li>Save the model as a-star</li> <li>Reset and Run the model. you should see that the operator’s path is through all the fixed object.</li> </ol> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/flexsim/astar/model-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/flexsim/astar/model-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/flexsim/astar/model-1400.webp"/> <img src="/assets/img/blog/flexsim/astar/model.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Model </div> <p>To avoid all the barriers and objects, drag A* tool from the navigation section in the object library and place it in the modeling surface.</p> <ol> <li>Double click the A* object and you should see a properties tab as shown below.</li> <li>In the members section, click the + button to add objects to the Traveler Members list. In this case select the operator1 in the operator section.</li> <li>Similarly add FR(Fixed Resource) Members and select all the fixed objects such as queue and processors.</li> </ol> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/flexsim/astar/navigator-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/flexsim/astar/navigator-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/flexsim/astar/navigator-1400.webp"/> <img src="/assets/img/blog/flexsim/astar/navigator.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Navigator Properties </div> <p>Reset and Run the model. Now the operator avoids the objects and takes the shortest path between the Source and Sink.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/flexsim/astar/model_run-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/flexsim/astar/model_run-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/flexsim/astar/model_run-1400.webp"/> <img src="/assets/img/blog/flexsim/astar/model_run.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Model run </div> <p>The blue box in the figure is an outline considered by A*. It can he hidden by unchecking in the visual tab of the A* Navigator properties box. A heat map shows the operator travel path frequency. So if you let the model run for a while you should see that the travel path in yellow to show high travel frequency on that path as opposed to green. To show heat map check the button in the visual tab of the A* Star Navigator properties box and you can play around with other option in the behaviour and visual tabs.</p> <p>An example of an You should a objects surrounding the sink and these are divider object. It s a set of line-segments in 3-dimensional space that creates either a one-way or two-barrier. The line segments are analogous to walls. These divider objects are in the same A* Navigation section in the object library.</p> <p>Drag divider from the A* Star Navigation section and place it similar to the figure below around the sink. Reset the model and run. The Operator should identify and follow a path between the Source and Sink that avoids the Barrier and Divider</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/flexsim/astar/astar_nodes-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/flexsim/astar/astar_nodes-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/flexsim/astar/astar_nodes-1400.webp"/> <img src="/assets/img/blog/flexsim/astar/astar_nodes.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> A * Nodes </div> <p>Using A* in FlexSim can be helpful in various scenarios where you need to optimize movement paths for entities, such as material handling equipment, robots, or workers within the simulation environment.</p>]]></content><author><name></name></author><category term="flexsim"/><category term="flexsim"/><summary type="html"><![CDATA[A-Star Algorithm]]></summary></entry><entry><title type="html">Flexsim: Simulation Experiment Control</title><link href="https://kamalpatell.github.io/blog/2023/flexsim-experiment-tool/" rel="alternate" type="text/html" title="Flexsim: Simulation Experiment Control"/><published>2023-07-18T18:30:00+00:00</published><updated>2023-07-18T18:30:00+00:00</updated><id>https://kamalpatell.github.io/blog/2023/flexsim-experiment-tool</id><content type="html" xml:base="https://kamalpatell.github.io/blog/2023/flexsim-experiment-tool/"><![CDATA[<h3 id="introduction">Introduction:</h3> <p>In my previous System Modeling with Flexsim post, I constructed a simulation model using flexsim object like fixed resources, task executor objects, port connections and to introduce variability to the model, I incorporated emperical distributions and visualized the data with dashboard charts. Using this existing model as an experimentation tool we can perform experimentations with various input parameters to influence the model’s performance measures.</p> <h3 id="project-overview">Project Overview:</h3> <p>For this we will use experimenter tool, to facilitate this experimentation, we will make use of several tools, including the input table or model parameter table. This table allows us to specify the values of different input parameters that we want to investigate.</p> <p>Additionally, we will utilize performance measure tables to aggregate and analyze the outputs that we are interested in. These tables help us track and evaluate the performance measures that we define as important for our simulation study.</p> <p>By employing these tools effectively, we can conduct experiments by modifying input parameters, running the simulation model, and analyzing the resulting performance measures. This iterative process allows us to gain insights into how changes in input parameters affect the desired performance outcomes.</p> <h3 id="experimentation">Experimentation:</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/flexsim/experiment/model-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/flexsim/experiment/model-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/flexsim/experiment/model-1400.webp"/> <img src="/assets/img/blog/flexsim/experiment/model.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Flexsim Model </div> <p>How can we use this model and learn something about the process and find where are the bottlenecks in the model ?</p> <p>Experimentation aims to automate the process of changing model parameters and observing their effects on model outputs. The parameters table and performance measure table are designed to formalize the inputs and outputs of interest in the experimentation workflow. By automating this process, experimenters can easily analyze the impact of parameter changes on the model’s outputs. Rather than manually adjusting inputs and observing outputs, the experimenter tool enables users to specify the parameters of interest and automatically track their effects on the desired outputs.</p> <p>The Experimenter tool facilitates running multiple iterations of a model rapidly, enabling efficient comparison of results and gaining a more comprehensive understanding of the model’s behavior. It automatically generates aggregated output reports, simplifying the process of comparing and analyzing the results. The tool provides valuable information such as average, minimum, maximum, and median values of performance measures, which aids in the analysis of the outputs of interest. These features enhance the ability to assess and interpret the model’s performance more effectively.</p> <h3 id="steps-to-successfull-analysis">Steps to Successfull Analysis</h3> <ol> <li>Prior to conducting experiments, it is crucial to have single run of the model, identifying and rectifying any issues such as extremes, omissions, outliers, or unexpected results to ensure the reliability and validity of subsequent experiments.</li> <li>Select a performance measure that accurately represents the purpose or focus of your model.</li> <li>Create or choose a new chart on your dashboard to report the selected performance measure.</li> <li>Identify the variables of interest that you intend to experiment with and include them in your model parameters.</li> <li>Add the Experimenter to your model and create a single Scenario experiment that will modify your Model Parameters.</li> <li>View results on “View Results” button on the Experimenter.</li> </ol> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/flexsim/experiment/baseline-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/flexsim/experiment/baseline-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/flexsim/experiment/baseline-1400.webp"/> <img src="/assets/img/blog/flexsim/experiment/baseline.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Baseline </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/flexsim/experiment/throughput-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/flexsim/experiment/throughput-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/flexsim/experiment/throughput-1400.webp"/> <img src="/assets/img/blog/flexsim/experiment/throughput.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Total Throughput </div> <p>The throughput figure above illustrates the performance of the system, showing that the throughput varies between a maximum of 44 and a minimum of 33. The median throughput value is 39, indicating the central tendency of the data. The calculated 95% confidence interval for the mean throughput is 37.8 to 40.2, giving us a range of values where we can reasonably expect the true mean to fall.</p> <ol> <li>Define additional Scenarios to evaluate the impact of Model Parameters. Its a good Practice to give scenarios meaningful names for better understanding. Rerun Experiments to see effects of Additional scenarios.</li> </ol> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/flexsim/experiment/scenerio-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/flexsim/experiment/scenerio-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/flexsim/experiment/scenerio-1400.webp"/> <img src="/assets/img/blog/flexsim/experiment/scenerio.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Add Scenerios to model </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/flexsim/experiment/throughputmulti-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/flexsim/experiment/throughputmulti-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/flexsim/experiment/throughputmulti-1400.webp"/> <img src="/assets/img/blog/flexsim/experiment/throughputmulti.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Multi-Throughput Scenerio </div> <ol> <li>Create A new Dashboard window and add the Scenario Chart and “point” it to any Charts you have made Examine results for model performance indicators.</li> </ol> <p>I constructed a scenerio to optimize maximum throughput, involving 3 operator machines and 3 processor machines with a 5% failure rate. After conducting the experiment, the staytime chart highlighted a bottleneck in queue 6, where boxes are delayed before being given to the combiner. Additionally, there is an issue with an excessive number of boxes passing through queue 5. Despite a reduction in staytime for queue 6 in pursuit of maximizing throughput, it became evident that the root cause lies in insufficient items passing through queue 6, negatively impacting overall throughput.</p> <p>Note: The staytime of a processor is defined as the (time the item leaves the processor) - (time item enters processor).</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/flexsim/experiment/total-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/flexsim/experiment/total-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/flexsim/experiment/total-1400.webp"/> <img src="/assets/img/blog/flexsim/experiment/total.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Total </div> <p>Scenerio chart for max throughput with avg staytime of each queue in the model.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/flexsim/experiment/scenerio_chart-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/flexsim/experiment/scenerio_chart-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/flexsim/experiment/scenerio_chart-1400.webp"/> <img src="/assets/img/blog/flexsim/experiment/scenerio_chart.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Scenerio Chart </div> <h3 id="conclusion">Conclusion</h3> <p>This project focused on using Flexsim simulation and the Experimenter tool to analyze the performance of a model. By conducting experiments and manipulating various input parameters, valuable insights were gained into the system’s behavior and potential bottlenecks were identified.</p> <p>Through the Experimenter tool, multiple scenarios were explored, and the impact of parameter changes on performance measures was assessed. This facilitated the identification of critical factors affecting system performance, providing a basis for optimization strategies.</p> <p>This project highlighted the importance of effective experimentation, selecting relevant performance measures, and utilizing dashboard visualization to facilitate data analysis and decision-making.</p> <p>Overall, the experience gained from this project enhances the understanding of simulation modeling and experimentation, enabling data-driven decision-making and potential improvements in various real-world scenarios.</p>]]></content><author><name></name></author><category term="flexsim"/><category term="flexsim"/><summary type="html"><![CDATA[Model as experimentation tool and learn about the model process with different input parameters.]]></summary></entry><entry><title type="html">System Modeling in Flexsim</title><link href="https://kamalpatell.github.io/blog/2023/system-modeling-flexsim/" rel="alternate" type="text/html" title="System Modeling in Flexsim"/><published>2023-07-15T16:00:00+00:00</published><updated>2023-07-15T16:00:00+00:00</updated><id>https://kamalpatell.github.io/blog/2023/system-modeling-flexsim</id><content type="html" xml:base="https://kamalpatell.github.io/blog/2023/system-modeling-flexsim/"><![CDATA[<h2 id="introduction">Introduction:</h2> <p>FlexSim, a cutting-edge simulation software, has revolutionized the way businesses approach process optimization and efficiency enhancement. Throughout my journey of learning and understanding FlexSim, I embarked on an exciting project that allowed me to explore the vast capabilities of this powerful tool. In this blog, I will provide a detailed layout of the FlexSim project I undertook, shedding light on my learning process, key challenges faced, and the valuable insights gained along the way.</p> <h2 id="project-overview">Project Overview:</h2> <p>In this project, I built a simple simulation model using FlexSim to gain hands-on experience with its components and functionalities. The model incorporated fixed resources, task executor objects, port connections, statistical distributions, labels, triggers, and data analysis through the pin dashboard feature. By simulating a basic system, I explored the behavior and efficiency of the simulated system, introduced variability through statistical distributions, and tracked relevant information using labels. The use of triggers, combiner objects, and dispatcher objects allowed for dynamic control, while the pin dashboard provided visual representations for data analysis. Through this project, I developed a solid foundation in FlexSim, equipping myself with valuable skills for future simulation modeling endeavors in process optimization and efficiency enhancement.</p> <h2 id="model-development">Model Development:</h2> <p>Considering the constraint of 30 models in the student version of FlexSim, I focused on building a small yet insightful simulation model. The model consists of a fixed resource source that generates flow items, which then pass through a separator object. The separator object randomly outputs items with a specified quantity using the dunifrom distribution. To add more variation, I included a trigger in the separator object to label and color the items upon exit. This resulted in different colored boxes representing the exiting items, with an empirical distribution assigned to each item using weights.</p> <p>The flow items then proceed to a queue and subsequently to a downstream processor. In the downstream processor, I utilized the lognormalmeanstdev distribution to set the process time for each item. Notably, each item was assigned its own mean and standard deviation using a global table, enabling individualized processing times based on specific characteristics.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/flexsim/system/model-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/flexsim/system/model-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/flexsim/system/model-1400.webp"/> <img src="/assets/img/blog/flexsim/system/model.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Model </div> <p>Following the downstream processor, the flow items proceed to another queue before being distributed to four separate queues based on their item types. Each queue represents a specific category of items within the simulation model. From the four queues, the items flow into a combiner belt, where a pallet from a source object combines the items together. This step simulates the process of assembling or packaging multiple items into a single unit.</p> <p>After the items are combined on the combiner belt, they continue to flow onto a conveyor belt. The conveyor belt serves as a means of transporting the combined items to their final destination. Finally, the items reach the sink object, which represents the end of the process or system being simulated. The sink object collects the items, signifying their completion or removal from the simulation model.</p> <p>Through this series of steps involving queues, combiner belts, conveyor belts, and a sink object, the simulation model replicates a process in which flow items are collected, combined, transported, and ultimately reach their final destination.</p> <p>By implementing this flow path within the simulation model, I gained hands-on experience in modeling system with multiple components and processes. This allowed me to explore the dynamics of item flow, queue management, and the overall efficiency of the simulated process.</p> <h2 id="results">Results:</h2> <p>After simulateing the model, I utilized various visual tools to showcase the outcomes of the simulation model built in FlexSim. By generating graphs, I was able to effectively analyze and present behavior of the simulated system.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/flexsim/system/content_time-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/flexsim/system/content_time-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/flexsim/system/content_time-1400.webp"/> <img src="/assets/img/blog/flexsim/system/content_time.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Content Time </div> <p>The graphs created provided valuable insights into key metrics such as throughput staytime, and much more advanced graphs can be create to analyze the system. These graphs allows to identify bottlenecks, and evaluate the overall efficiency of the simulated process. By analyzing the data represented in the graphs, we can make informed observations and draw conclusions regarding system performance and potential areas for improvement.</p> <p>Below are some other graphs that I created to further analyze and visualize the results of the simulation model</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/flexsim/system/throughput-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/flexsim/system/throughput-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/flexsim/system/throughput-1400.webp"/> <img src="/assets/img/blog/flexsim/system/throughput.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Throughput </div> <p>In FlexSim, “State” represents the current condition of an entity, while “Staytime” refers to the time an entity remains in a specific location. State helps track entity progress, while Staytime controls entity duration in a process or location.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/flexsim/system/state-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/flexsim/system/state-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/flexsim/system/state-1400.webp"/> <img src="/assets/img/blog/flexsim/system/state.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> State </div> <p><br/></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/flexsim/system/staytime-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/flexsim/system/staytime-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/flexsim/system/staytime-1400.webp"/> <img src="/assets/img/blog/flexsim/system/staytime.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Staytime </div> <p>Overall, a comprehensive analysis of the simulation model’s performance and behavior using bar charts, line charts box plot, Gantt Chart etc. By combining quantitative data with visual representations, we can effectively communicate the insights gained from the simulation runs. These results serve as a valuable resource for further analysis, decision-making, and potential optimization efforts in real-world scenarios.</p> <p>Despite the model’s simplicity, it provides a valuable learning opportunity by incorporating various distribution types, triggers, labels, and dynamic attributes. Through this model, I gained practical experience in utilizing statistical distributions, global tables, and object properties to simulate real-world scenarios. This foundation will prove beneficial as I progress to more complex simulation projects in the future.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/flexsim/system/flexSim_gif.gif-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/flexsim/system/flexSim_gif.gif-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/flexsim/system/flexSim_gif.gif-1400.webp"/> <img src="/assets/img/blog/flexsim/system/flexSim_gif.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Model Output </div>]]></content><author><name></name></author><category term="flexsim"/><category term="flexsim"/><summary type="html"><![CDATA[Introduction:]]></summary></entry><entry><title type="html">Jet Engine with PTC/Creo</title><link href="https://kamalpatell.github.io/blog/2023/jet-engine-cad/" rel="alternate" type="text/html" title="Jet Engine with PTC/Creo"/><published>2023-06-30T15:12:00+00:00</published><updated>2023-06-30T15:12:00+00:00</updated><id>https://kamalpatell.github.io/blog/2023/jet-engine-cad</id><content type="html" xml:base="https://kamalpatell.github.io/blog/2023/jet-engine-cad/"><![CDATA[<h3 id="jet-engine">Jet Engine</h3> <p><strong>Built using PTC Creo</strong></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/cad/jet_engine-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/cad/jet_engine-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/cad/jet_engine-1400.webp"/> <img src="/assets/img/blog/cad/jet_engine.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/cad/jet_engine_case-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/cad/jet_engine_case-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/cad/jet_engine_case-1400.webp"/> <img src="/assets/img/blog/cad/jet_engine_case.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Jet Enginee Assembly </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/cad/jet_front-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/cad/jet_front-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/cad/jet_front-1400.webp"/> <img src="/assets/img/blog/cad/jet_front.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blog/cad/jet_rear-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blog/cad/jet_rear-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blog/cad/jet_rear-1400.webp"/> <img src="/assets/img/blog/cad/jet_rear.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Front(left) and Rear(right) of Jet Engine </div> <p><strong>Check my other cad model at <a href="https://grabcad.com/kamal.patel-2">GrabCAD</a></strong></p>]]></content><author><name></name></author><category term="ptc-creo"/><category term="CAD"/><summary type="html"><![CDATA[Practice CAD modeling in Creo software.]]></summary></entry></feed>